{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbfd7d14",
   "metadata": {},
   "source": [
    "### 1.3.1 Example - Weighted Sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435dc8a9",
   "metadata": {},
   "source": [
    "Plain weighted sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13aaf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxtyping import Float\n",
    "import torch\n",
    "\n",
    "def weighted_sum(\n",
    "    x: Float[torch.Tensor, \"... D\"],\n",
    "    weight: Float[torch.Tensor, \"D\"],\n",
    "):\n",
    "    \"\"\"\n",
    "    Given an input matrix X, weâ€™ll multiply its entries by a \n",
    "    column-wise weight vector w, and sum each row,\n",
    "    giving us the matrix-vector product of X and w.\n",
    "    \"\"\"\n",
    "    return (weight * x).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b8129",
   "metadata": {},
   "source": [
    "Triton tiled forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcd8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "@triton.jit\n",
    "def weighted_sum_fwd(\n",
    "    x_ptr, weight_ptr,  # input pointers\n",
    "    output_ptr, # output pointer\n",
    "    x_stride_row, x_stride_dim, # strides tell us how to move one element in each axis of a tensor\n",
    "    weight_stride_dim,  # likely 1\n",
    "    output_stride_row,  # likely 1\n",
    "    ROWS, D,\n",
    "    ROWS_TILE_SIZE: tl.constexpr, D_TILE_SIZE: tl.constexpr,    # tile shapes must be known at compile time\n",
    "):\n",
    "    # Each instance will compute the weighted sum of a tile of rows of x.\n",
    "    # `tl.program_id` gives us a way to check which thread block we're running in\n",
    "    row_tile_idx = tl.program_id(0)\n",
    "\n",
    "    # Block pointers give us a way to select from an ND region of memory\n",
    "    # and move our selection around.\n",
    "    # The block pointer must know:\n",
    "    # - The pointer to the first element of the tensor\n",
    "    # - The overall shape of the tensor to handle out-of-bounds access\n",
    "    # - The strides of each dimension to use the memory layout properly\n",
    "    # - The ND coordinates of the starting block, i.e., \"offsets\"\n",
    "    # - The block shape to use load/store at a time\n",
    "    # - The order of the dimensions in memory from major to minor\n",
    "    #   axes (= np.argsort(strides)) for optimizations, especially useful on H100\n",
    "    x_block_ptr = tl.make_block_ptr(\n",
    "        x_ptr,\n",
    "        shapes=(ROWS, D, ),\n",
    "        strides=(x_stride_row, x_stride_dim),\n",
    "        offsets=(row_tile_idx * ROWS_TILE_SIZE, 0),\n",
    "        block_shape=(ROWS_TILE_SIZE, D_TILE_SIZE),\n",
    "        order=(1, 0),\n",
    "    )\n",
    "\n",
    "    weight_block_ptr = tl.make_block_ptr(\n",
    "        weight_ptr,\n",
    "        shapes=(D,),\n",
    "        strides=(weight_stride_dim,),\n",
    "        offsets=(0,),\n",
    "        block_shape=(D_TILE_SIZE,),\n",
    "        order=(0,)\n",
    "    )\n",
    "\n",
    "    output_block_ptr = tl.make_block_ptr(\n",
    "        output_ptr,\n",
    "        shapes=(ROWS,),\n",
    "        strides=(output_stride_row,),\n",
    "        offsets=(row_tile_idx * ROWS_TILE_SIZE,),\n",
    "        block_shape=(ROWS_TILE_SIZE,),\n",
    "        order=(0,)\n",
    "    )\n",
    "\n",
    "    # Initialize a buffer to write to\n",
    "    output = tl.zeros((ROWS_TILE_SIZE,), dtype=tl.float32)\n",
    "\n",
    "    for i in range(tl.cdiv(D, D_TILE_SIZE)):\n",
    "        # Load the current block pointer\n",
    "        # Since ROWS_TILE_SIZE might not divice ROWS, and D_TILE_SIZE might not divide D,\n",
    "        # we need boundary checks for both dimensions\n",
    "        row = tl.load(x_block_ptr, boundary_check=(0, 1), padding_option=\"zero\")    # (ROWS_TILE_SIZE, D_TILE_SIZE)\n",
    "        weight = tl.load()  # (D_TILE_SIZE,)\n",
    "\n",
    "        # compute the weighted sum of the row\n",
    "        output += tl.sum(row * weight[None, :], axis=1)\n",
    "\n",
    "        # move the pointers to the next tile\n",
    "        # these are (rows, columns) coordinate deltas\n",
    "        x_block_ptr = x_block_ptr.advance((0, D_TILE_SIZE)) # mode by D_TILE_SIZE in the last dimension\n",
    "        weight_block_ptr = weight_block_ptr.advance((D_TILE_SIZE,)) # move by D_TILE_SIZE\n",
    "\n",
    "    # Write output to the output block pointer (a single scalar per row)\n",
    "    # Since ROWS_TILE_SIZE might not divide ROWS, we need boundary checks\n",
    "    tl.store(output_block_ptr, output, boundary_check=(0,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18623d4",
   "metadata": {},
   "source": [
    "Backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9284e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def weighted_sum_backward(\n",
    "    x_ptr, weight_ptr,  # input\n",
    "    grad_output_ptr,    # grad input\n",
    "    grad_x_ptr, partial_grad_weight_ptr,    # grad outputs\n",
    "    stride_xr, stride_xd,\n",
    "    stride_wd,\n",
    "    stride_gr,\n",
    "    stride_gxr, stride_gxd,\n",
    "    stride_gwb, stride_gwd,\n",
    "    NUM_ROWS, D,\n",
    "    ROWS_TILE_SIZE: tl.constexpr, D_TILE_SIZE: tl.constexpr,\n",
    "):\n",
    "    row_tile_idx = tl.program_id(0)\n",
    "    n_row_tiles = tl.num_programs(0)\n",
    "\n",
    "    # Inputs\n",
    "    grad_output_block_ptr = tl.make_block_ptr(\n",
    "        grad_output_ptr,\n",
    "        shape=(NUM_ROWS,), strides=(stride_gr,),\n",
    "        offsets=(row_tile_idx * ROWS_TILE_SIZE),\n",
    "        block_shape=(ROWS_TILE_SIZE,),\n",
    "        order=(0,),\n",
    "    )\n",
    "\n",
    "    x_block_ptr = tl.make_block_ptr(\n",
    "        x_ptr,\n",
    "        shape=(NUM_ROWS, D, ), strides=(stride_xr, stride_xd),\n",
    "        offsets=(row_tile_idx * ROWS_TILE_SIZE, 0),\n",
    "        block_shape=(ROWS_TILE_SIZE, D_TILE_SIZE),\n",
    "        order=(1, 0),\n",
    "    )\n",
    "\n",
    "    weight_block_ptr = tl.make_block_ptr(\n",
    "        weight_ptr,\n",
    "        shape=(D,), strides=(stride_wd,),\n",
    "        offsets=(0,), block_shape=(D_TILE_SIZE,),\n",
    "        order=(0,),\n",
    "    )\n",
    "\n",
    "    grad_x_block_ptr = tl.make_block_ptr(\n",
    "        grad_x_ptr,\n",
    "        shape=(NUM_ROWS, D, ), strides=(stride_gxr, stride_gxd),\n",
    "        offsets=(row_tile_idx * ROWS_TILE_SIZE, 0),\n",
    "        block_shape=(ROWS_TILE_SIZE, D_TILE_SIZE),\n",
    "        order=(1, 0),\n",
    "    )\n",
    "\n",
    "    partial_grad_weight_block_ptr = tl.make_block_ptr(\n",
    "        partial_grad_weight_ptr,\n",
    "        shape=(n_row_tiles, D), strides=(stride_gwb, stride_gwd),\n",
    "        offsets=(row_tile_idx, 0),\n",
    "        block_shape=(1, D_TILE_SIZE),\n",
    "        order=(1, 0),\n",
    "    )\n",
    "\n",
    "    for i in range(tl.cdiv(D, D_TILE_SIZE)):\n",
    "        grad_output = tl.load(grad_output_block_ptr, boundary_check=(0,), padding_option=\"zero\") # (ROWS_TILE_SIZE,)\n",
    "\n",
    "        # Outer product for grad_x\n",
    "        weight = tl.load(weight_block_ptr, boundary_check=(0,), padding_option=\"zero\") # (D_TILE_SIZE,)\n",
    "        grad_x_row = grad_output[:, None] * weight[None, :]\n",
    "        tl.store(grad_x_block_ptr, grad_x_row, boundary_check=(0, 1))\n",
    "\n",
    "        # Reduce as many rows as possible for the grad_weight result\n",
    "        row = tl.load(x_block_ptr, boundary_check=(0, 1), padding_option=\"zero\") # (ROWS_TILE_SIZE, D_TILE_SIZE)\n",
    "        grad_weight_row = tl.sum(row * grad_output[:, None], axis=0, padding_option=\"zero\")\n",
    "        tl.sotre(partial_grad_weight_block_ptr, grad_weight_row, boundary_check=(1,)) # never out of bounds for dim 0\n",
    "\n",
    "        # Move block pointers to next tile along D\n",
    "        x_block_ptr = x_block_ptr.advance((0, D_TILE_SIZE))\n",
    "        weight_block_ptr = weight_block_ptr.advance((D_TILE_SIZE,))\n",
    "        partial_grad_weight_block_ptr = partial_grad_weight_block_ptr.advance((0, D_TILE_SIZE))\n",
    "        grad_x_block_ptr = grad_x_block_ptr.advance((0, D_TILE_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ec0a9",
   "metadata": {},
   "source": [
    "Now, we wrap this kernel in a PyTorch Autograd function that will interoperate with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "class WeightedSumFunc(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, weight):\n",
    "        # Cache x and weight to be used in the backward pass, when we\n",
    "        # only receive the gradient wrt. the output tensor, and\n",
    "        # need to compute the gradients wrt. x and weight.\n",
    "        D, output_dims = x.shape[-1], x.shape[:-1]\n",
    "\n",
    "        # Reshape input tensor into 2D\n",
    "        input_shape = x.shape\n",
    "        x = rearrange(x, \"... d -> (...) d\")\n",
    "\n",
    "        ctx.save_for_backward(x, weight)\n",
    "\n",
    "        assert len(weight.shape) == 1 and weight.shape[0] == D, \"Dimension mismatch\"\n",
    "        assert x.is_cuda and weight.is_cuda, \"Expected CUDA tensors\"\n",
    "        assert x.is_contiguous(), \"Our pointer arithmetic will assume contiguous x\"\n",
    "\n",
    "        ctx.D_TILE_SIZE = triton.next_power_of_2(D) // 16   # Roughly 16 loops through the embedding dimension\n",
    "        ctx.ROWS_TILE_SIZE = 16 # Each thread processes 16 batch elements at a time\n",
    "        ctx.input_shape = input_shape\n",
    "\n",
    "        # Need to initialize empty result tensor. Note that these elements are not necessarily 0!\n",
    "        y = torch.empty(output_dims, device=x.device)\n",
    "\n",
    "        # Launch our kernel with n instances in our 1D grid\n",
    "        n_rows = y.numel()\n",
    "        weighted_sum_fwd[(tl.cdiv(n_rows, ctx.ROWS_TILE_SIZE),)](\n",
    "            x, weight,\n",
    "            y,\n",
    "            x.stride(0), x.stride(1),\n",
    "            weight.stride(0),\n",
    "            y.stride(0),\n",
    "            ROWS=n_rows, D=D,\n",
    "            ROWS_TILE_SIZE=ctx.ROWS_TILE_SIZE, D_TILE_SIZE=ctx.D_TILE_SIZE\n",
    "        )\n",
    "\n",
    "        return y.view(input_shape[:-1])\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_out):\n",
    "        x, weight = ctx.saved_tensors\n",
    "        ROWS_TILE_SIZE, D_TILE_SIZE = ctx.ROWS_TILE_SIZE, ctx.D_TILE_SIZE # These don't have to be the same\n",
    "        n_rows, D = x.shape\n",
    "\n",
    "        # Our strategy is for each thread block to first write to a partial buffer,\n",
    "        # then we reduce over this buffer to get the final gradient\n",
    "        partial_grad_weight = torch.empty((tl.cdiv(n_rows, ROWS_TILE_SIZE), D), device=x.device, dtype=x.dtype)\n",
    "        grad_x = torch.empty_like(x)\n",
    "\n",
    "        weighted_sum_backward[(tl.cdiv(n_rows, ROWS_TILE_SIZE),)](\n",
    "            x, weight,\n",
    "            grad_out,\n",
    "            grad_x, partial_grad_weight,\n",
    "            x.stride(0), x.stride(1),\n",
    "            weight.stride(0),\n",
    "            grad_out.stride(0),\n",
    "            grad_x.stride(0), grad_x.stride(1),\n",
    "            partial_grad_weight.stride(0), partial_grad_weight.stride(1),\n",
    "            NUM_ROWS=n_rows, D_TILE_SIZE=D_TILE_SIZE,\n",
    "        )\n",
    "        grad_weight = partial_grad_weight.sum(axis=0)\n",
    "        return grad_x, grad_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12737785",
   "metadata": {},
   "source": [
    "Finally, we can now obtain a function that works much like those implemented in torch.nn.functional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9439dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_weightedsum = WeightedSumFunc.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\"\n",
    "x = torch.randn((50, 10), device=device)\n",
    "w = torch.randn((10,), device=device)\n",
    "out = f_weightedsum(x, w)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
