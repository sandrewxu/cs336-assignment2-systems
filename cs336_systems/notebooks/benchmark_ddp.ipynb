{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab558ab",
   "metadata": {},
   "source": [
    "# 2 Distributed Data Parallel Training\n",
    "\n",
    "## 2.1 Single-Node Distributed Communication in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5fac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "def distributed_demo(rank, world_size):\n",
    "    setup(rank, world_size)\n",
    "    data = torch.randint(0, 10, (3,))\n",
    "    print(f\"rank {rank} data (before all-reduce): {data}\")\n",
    "    dist.all_reduce(data, async_op=False)\n",
    "    print(f\"rank {rank} data (after all-reduce): {data}\")\n",
    "\n",
    "world_size = 4\n",
    "mp.spawn(fn=distributed_demo, args=(world_size,), nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c72749",
   "metadata": {},
   "source": [
    "Node: a machine on the network\n",
    "\n",
    "Worker: an instance of a program that is participating in the distributed training. In this assignment, each worker will have a single process, so we will use worker, process, and worker process interchangeably. However, a worker may use multiple processes in practice.\n",
    "\n",
    "World size: the number of total workers in a process group.\n",
    "\n",
    "Global rank: an integer ID (between 0 and world_size-1) that uniquely identifies a worker in the process group. For example, for world size two, one process will have rank 0 (the master process) and the other process will have rank 1.\n",
    "\n",
    "Local world size: When running applications across different nodes, the local world size is the number of workers running locally on a given node. For example, if we have an application that spawns 4 workers on 2 nodes each, the world size would be 8 and the local world size would be 4. When running on a single node, the local world size is equivalent to the global world size.\n",
    "\n",
    "Local rank: An integer ID (between 0 and local_world_size-1) that uniquely identifies the index of a local worker on the machine.\n",
    "\n",
    "### 2.1.1 Best Practices for Benchmarking Distributed Applications\n",
    "\n",
    "Throughout this portion of the assignment you will be benchmarking distributed applications to better understand the overhead from communication. Here are a few best practices:\n",
    "- Whenever possible, run benchmarks on the same machine to facilitate controlled comparisons.\n",
    "- Perform several warm-up steps before timing the operation of interest. This is especially important for NCCL communication calls. 5 iterations of warmup is generally sufficient.\n",
    "- Call torch.cuda.synchronize() to wait for CUDA operations to complete when benchmarking on GPUs. Note that this is necessary even when calling communication operations with async_op=False, which returns when the operation is queued on the GPU (as opposed to when the communication actually finishes)\n",
    "- Timings may vary slightly across different ranks, so itâ€™s common to aggregate measurements across ranks to improve estimates. You may find the all-gather collective (specifically the dist.all_gather_object function) to be useful for collecting results from all ranks.\n",
    "- In general, debug locally with Gloo on CPU, and then as required in a given problem, benchmark with NCCL on GPU. Switching between the backends just involves changing the init_process_group call and tensor device casts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f563b40",
   "metadata": {},
   "source": [
    "**Benchmark Results (Macbook)**\n",
    "\n",
    "| Backend | Workers | Data Size | Time (s)      |\n",
    "|---------|---------|-----------|---------------|\n",
    "| gloo    | 2       | 1MB       | 0.002193      |\n",
    "| gloo    | 2       | 10MB      | 0.011302      |\n",
    "| gloo    | 2       | 100MB     | 0.091152      |\n",
    "| gloo    | 2       | 1000MB    | 0.893033      |\n",
    "| gloo    | 4       | 1MB       | 0.004053      |\n",
    "| gloo    | 4       | 10MB      | 0.022453      |\n",
    "| gloo    | 4       | 100MB     | 0.226364      |\n",
    "| gloo    | 4       | 1000MB    | 2.076443      |\n",
    "| gloo    | 6       | 1MB       | 0.007497      |\n",
    "| gloo    | 6       | 10MB      | 0.036168      |\n",
    "| gloo    | 6       | 100MB     | 0.382041      |\n",
    "| gloo    | 6       | 1000MB    | 3.864817      |\n",
    "| **NCCL** | -      | -         | Skipping NCCL: CUDA not available. |\n",
    "\n",
    "**Benchmark Results (HPC)**\n",
    "GPUs were full."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34ffac5",
   "metadata": {},
   "source": [
    "## 2.2 A Naive Implementation of Distributed Data Parallel Training\n",
    "\n",
    "\n",
    "| Metric              | Naive           | Flat            | Overlap         |\n",
    "|:--------------------|:----------------|:----------------|:----------------|\n",
    "| model               | xl              | xl              | xl              |\n",
    "| backend             | nccl            | nccl            | nccl            |\n",
    "| world_size          | 2               | 2               | 2               |\n",
    "| global_batch_size   | 4               | 4               | 4               |\n",
    "| warmup_steps        | 5               | 5               | 5               |\n",
    "| benchmark_steps     | 10              | 10              | 10              |\n",
    "| step_time_avg_s     | 0.4166874293936417   | 0.41147000561468305   | 0.355364911374636      |\n",
    "| step_time_std_s     | 0.00018683517882813022 | 0.0005754676821822966 | 0.00040293421827531745 |\n",
    "| comm_time_avg_s     | 0.09035780989797786    | 0.0848893636954017    | 0.0011527655879035592  |\n",
    "| comm_time_std_s     | 0.000104253896714834   | 0.0005444497450712978 | 0.00011374137002487174 |\n",
    "| comm_frac_avg       | 0.21684792522827329    | 0.2063061437328047    | 0.0032438155791756707  |\n",
    "| comm_frac_std       | 0.00021810614287490294 | 0.0010456305515322477 | 0.00031916462254377004 |\n",
    "\n",
    "## 2.3 Improving Upon the Minimal DDP Implementation\n",
    "\n",
    "|                   | 0                      | 1                      | 2                      | 3                      |\n",
    "|:------------------|:-----------------------|:-----------------------|:-----------------------|:-----------------------|\n",
    "| bucket_size       | 1                      | 10                     | 100                    | 1000                   |\n",
    "| model             | xl                     | xl                     | xl                     | xl                     |\n",
    "| backend           | nccl                   | nccl                   | nccl                   | nccl                   |\n",
    "| world_size        | 2                      | 2                      | 2                      | 2                      |\n",
    "| global_batch_size | 4                      | 4                      | 4                      | 4                      |\n",
    "| warmup_steps      | 5                      | 5                      | 5                      | 5                      |\n",
    "| benchmark_steps   | 10                     | 10                     | 10                     | 10                     |\n",
    "| step_time_avg_s   | 0.35737448240397496    | 0.3586082030669786     | 0.3521354146883823     | 0.35815223670797425    |\n",
    "| step_time_std_s   | 0.00045482918231892186 | 0.00023495819585062406 | 0.00018689529789812692 | 0.0003563481417223787  |\n",
    "| comm_time_avg_s   | 0.0017477366141974925  | 0.0014774692826904356  | 0.0008597417967393994  | 0.0006798887276090682  |\n",
    "| comm_time_std_s   | 0.00012864381462239098 | 0.00012264102032681393 | 7.771309629903895e-05  | 4.797181851323098e-05  |\n",
    "| comm_frac_avg     | 0.004890260091267846   | 0.004119833181109983   | 0.0024415040799994334  | 0.0018983396234894985  |\n",
    "| comm_frac_std     | 0.0003561744808705491  | 0.00033953065310998607 | 0.0002206324158818065  | 0.00013422975145629642 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35dc98ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                   | 0                      | 1                      | 2                      | 3                      |\n",
      "|:------------------|:-----------------------|:-----------------------|:-----------------------|:-----------------------|\n",
      "| bucket_size       | 1                      | 10                     | 100                    | 1000                   |\n",
      "| model             | xl                     | xl                     | xl                     | xl                     |\n",
      "| backend           | nccl                   | nccl                   | nccl                   | nccl                   |\n",
      "| world_size        | 2                      | 2                      | 2                      | 2                      |\n",
      "| global_batch_size | 4                      | 4                      | 4                      | 4                      |\n",
      "| warmup_steps      | 5                      | 5                      | 5                      | 5                      |\n",
      "| benchmark_steps   | 10                     | 10                     | 10                     | 10                     |\n",
      "| step_time_avg_s   | 0.35737448240397496    | 0.3586082030669786     | 0.3521354146883823     | 0.35815223670797425    |\n",
      "| step_time_std_s   | 0.00045482918231892186 | 0.00023495819585062406 | 0.00018689529789812692 | 0.0003563481417223787  |\n",
      "| comm_time_avg_s   | 0.0017477366141974925  | 0.0014774692826904356  | 0.0008597417967393994  | 0.0006798887276090682  |\n",
      "| comm_time_std_s   | 0.00012864381462239098 | 0.00012264102032681393 | 7.771309629903895e-05  | 4.797181851323098e-05  |\n",
      "| comm_frac_avg     | 0.004890260091267846   | 0.004119833181109983   | 0.0024415040799994334  | 0.0018983396234894985  |\n",
      "| comm_frac_std     | 0.0003561744808705491  | 0.00033953065310998607 | 0.0002206324158818065  | 0.00013422975145629642 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_1 = {'bucket_size': 1, 'model': 'xl', 'backend': 'nccl', 'world_size': 2, 'global_batch_size': 4, 'warmup_steps': 5, 'benchmark_steps': 10, 'step_time_avg_s': 0.35737448240397496, 'step_time_std_s': 0.00045482918231892186, 'comm_time_avg_s': 0.0017477366141974925, 'comm_time_std_s': 0.00012864381462239098, 'comm_frac_avg': 0.004890260091267846, 'comm_frac_std': 0.0003561744808705491}\n",
    "results_10 = {'bucket_size': 10, 'model': 'xl', 'backend': 'nccl', 'world_size': 2, 'global_batch_size': 4, 'warmup_steps': 5, 'benchmark_steps': 10, 'step_time_avg_s': 0.3586082030669786, 'step_time_std_s': 0.00023495819585062406, 'comm_time_avg_s': 0.0014774692826904356, 'comm_time_std_s': 0.00012264102032681393, 'comm_frac_avg': 0.004119833181109983, 'comm_frac_std': 0.00033953065310998607}\n",
    "results_100 = {'bucket_size': 100, 'model': 'xl', 'backend': 'nccl', 'world_size': 2, 'global_batch_size': 4, 'warmup_steps': 5, 'benchmark_steps': 10, 'step_time_avg_s': 0.3521354146883823, 'step_time_std_s': 0.00018689529789812692, 'comm_time_avg_s': 0.0008597417967393994, 'comm_time_std_s': 7.771309629903895e-05, 'comm_frac_avg': 0.0024415040799994334, 'comm_frac_std': 0.0002206324158818065}\n",
    "results_1000 = {'bucket_size': 1000, 'model': 'xl', 'backend': 'nccl', 'world_size': 2, 'global_batch_size': 4, 'warmup_steps': 5, 'benchmark_steps': 10, 'step_time_avg_s': 0.35815223670797425, 'step_time_std_s': 0.0003563481417223787, 'comm_time_avg_s': 0.0006798887276090682, 'comm_time_std_s': 4.797181851323098e-05, 'comm_frac_avg': 0.0018983396234894985, 'comm_frac_std': 0.00013422975145629642}\n",
    "\n",
    "\n",
    "df = pd.DataFrame([results_1, results_10, results_100, results_1000]).transpose()\n",
    "print(df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505be27c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
